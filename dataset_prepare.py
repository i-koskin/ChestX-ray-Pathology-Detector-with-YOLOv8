import pandas as pd
from pathlib import Path
from collections import Counter, defaultdict
import shutil
import math
import random
from PIL import Image

# –ö–ª–∞—Å—Å—ã
CLASSES = [
    "Atelectasis",
    "Cardiomegaly",
    "Effusion",
    "Infiltrate",
    "Mass",
    "Nodule",
    "Pneumonia",
    "Pneumothorax"
]


def prepare_dataset_with_median_oversampling(
        csv_path: str,
        images_src_dir: str,
        output_dir: str,
        val_ratio: float = 0.15,
        random_seed: int = 42
):
    """
    –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –¥–∞—Ç–∞—Å–µ—Ç YOLO —Å –∞–¥–∞–ø—Ç–∏–≤–Ω—ã–º oversampling –¥–æ –º–µ–¥–∏–∞–Ω—ã.

    Args:
        csv_path: –ø—É—Ç—å –∫ BBox_List_2017.csv
        images_src_dir: –ø–∞–ø–∫–∞ —Å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è–º–∏ ('./dataset/images')
        output_dir: –≤—ã—Ö–æ–¥–Ω–∞—è –ø–∞–ø–∫–∞ –¥–ª—è YOLO-—Ñ–æ—Ä–º–∞—Ç–∞
        val_ratio: –¥–æ–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ (–±–µ–∑ oversampling!)
        random_seed: –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
    """
    # 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ø—É—Ç–µ–π
    Path(output_dir).mkdir(parents=True, exist_ok=True)
    for split in ["train", "val"]:
        (output_dir / "images" / split).mkdir(parents=True, exist_ok=True)
        (output_dir / "labels" / split).mkdir(parents=True, exist_ok=True)

    # 2. –ó–∞–≥—Ä—É–∑–∫–∞ –∞–Ω–Ω–æ—Ç–∞—Ü–∏–π
    df = pd.read_csv(csv_path)
    grouped = df.groupby('Image Index')

    # –£–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ –∏—Ö –∫–ª–∞—Å—Å—ã
    img_to_labels = {}
    for img_id, group in grouped:
        img_to_labels[img_id] = group['Finding Label'].unique().tolist()

    # 3. –ü–æ–¥—Å—á—ë—Ç —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –Ω–∞ –∫–ª–∞—Å—Å
    class_counts = Counter()
    for labels in img_to_labels.values():
        for label in labels:
            class_counts[label] += 1

    print("–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ oversampling (—É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è):")
    for cls, cnt in sorted(class_counts.items()):
        print(f"  {cls:15}: {cnt}")

    # 4. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ —Ü–µ–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è ‚Äî –º–µ–¥–∏–∞–Ω–∞
    counts_list = list(class_counts.values())
    target_count = int(pd.Series(counts_list).median())
    print(f"\nüéØ –¶–µ–ª–µ–≤–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ –∫–ª–∞—Å—Å (–º–µ–¥–∏–∞–Ω–∞): {target_count}")

    # 5. –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç–æ–≤ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
    repeat_factors = {}
    for cls, cnt in class_counts.items():
        if cnt >= target_count:
            repeat_factors[cls] = 1.0  # –Ω–µ –ø–æ–≤—Ç–æ—Ä—è–µ–º
        else:
            # –ù–∞–ø—Ä–∏–º–µ—Ä: cnt=60, target=200 ‚Üí factor ‚âà 3.33 ‚Üí ceil ‚Üí 4
            repeat_factors[cls] = target_count / cnt

    # 6. –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ, —Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –≤–∫–ª—é—á–∞—Ç—å –∫–∞–∂–¥–æ–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
    img_repeat_map = {}
    for img_id, labels in img_to_labels.items():
        # –ë–µ—Ä—ë–º –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π —Ñ–∞–∫—Ç–æ—Ä —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –∫–ª–∞—Å—Å–æ–≤ –Ω–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–∏
        max_factor = max(repeat_factors[label] for label in labels)
        img_repeat_map[img_id] = math.ceil(max_factor)

    # 7. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ –Ω–∞ train/val (–¥–æ oversampling!)
    random.seed(random_seed)
    all_img_ids = list(img_to_labels.keys())
    random.shuffle(all_img_ids)

    n_val = int(val_ratio * len(all_img_ids))
    val_ids = set(all_img_ids[:n_val])
    train_ids = [img for img in all_img_ids if img not in val_ids]

    # –ü—Ä–∏–º–µ–Ω—è–µ–º oversampling –∫ train
    train_with_repeats = []
    for img_id in train_ids:
        repeat = img_repeat_map[img_id]
        for i in range(repeat):
            train_with_repeats.append((img_id, i))  # (id, –∫–æ–ø–∏—è_–Ω–æ–º–µ—Ä)

    print(f"\nüìä –ü–æ—Å–ª–µ oversampling:")
    print(f"  Train –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (—Å –∫–æ–ø–∏—è–º–∏): {len(train_with_repeats)}")
    print(f"  Val –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π (–æ—Ä–∏–≥–∏–Ω–∞–ª—ã):   {len(val_ids)}")

    # 8. –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –∏ —Å–æ–∑–¥–∞–Ω–∏–µ .txt
    def copy_image_and_label(img_id: str, split: str, copy_id: int = None):
        src_img = images_src_dir / img_id
        if not src_img.exists():
            print(f"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω–æ: {img_id} –Ω–µ –Ω–∞–π–¥–µ–Ω–æ")
            return

        # –ù–æ–≤–æ–µ –∏–º—è: –µ—Å–ª–∏ –∫–æ–ø–∏—è ‚Äî –¥–æ–±–∞–≤–ª—è–µ–º —Å—É—Ñ—Ñ–∏–∫—Å
        stem = Path(img_id).stem
        suffix = f"_{copy_id}" if copy_id is not None else ""
        ext = src_img.suffix
        new_name = f"{stem}{suffix}{ext}"

        # –ö–æ–ø–∏—Ä—É–µ–º –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ
        dst_img = output_dir / "images" / split / new_name
        shutil.copy(src_img, dst_img)

        # –°–æ–∑–¥–∞—ë–º .txt –∞–Ω–Ω–æ—Ç–∞—Ü–∏—é
        anns = grouped.get_group(img_id)
        w_img, h_img = Image.open(src_img).size

        label_path = output_dir / "labels" / split / f"{stem}{suffix}.txt"
        with open(label_path, "w") as f:
            for _, row in anns.iterrows():
                x = row['Bbox [x']
                y = row['y']
                w = row['w']
                h = row['h]']

                # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º
                xc = (x + w / 2) / w_img
                yc = (y + h / 2) / h_img
                wn = w / w_img
                hn = h / h_img
                cls_id = CLASSES.index(row['Finding Label'])
                f.write(f"{cls_id} {xc:.6f} {yc:.6f} {wn:.6f} {hn:.6f}\n")

    # 9. –û–±—Ä–∞–±–æ—Ç–∫–∞ train –∏ val
    print("\nüì§ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ train...")
    for img_id, copy_id in train_with_repeats:
        copy_image_and_label(img_id, "train", copy_id)

    print("üì§ –ö–æ–ø–∏—Ä–æ–≤–∞–Ω–∏–µ val...")
    for img_id in val_ids:
        copy_image_and_label(img_id, "val")

    # 10. –°–æ–∑–¥–∞–Ω–∏–µ data.yaml
    yaml_content = f"""train: ./images/train
val: ./images/val
nc: {len(CLASSES)}
names: {CLASSES}
"""
    with open(output_dir / "data.yaml", "w") as f:
        f.write(yaml_content)

    print(f"\n‚úÖ –î–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤: {output_dir}")
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ train: {len(train_with_repeats)}")
    print(f"   –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–π –≤ val:   {len(val_ids)}")


if __name__ == "__main__":

    CSV_PATH = "./BBox_List_2017.csv"
    IMG_SRC = Path("./dataset/images")
    OUTPUT_DIR = Path("chestxray_yolo")

    prepare_dataset_with_median_oversampling(
        csv_path=CSV_PATH,
        images_src_dir=IMG_SRC,
        output_dir=OUTPUT_DIR
    )
